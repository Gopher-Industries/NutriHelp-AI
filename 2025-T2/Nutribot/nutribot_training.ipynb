{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3bbc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import chromadb\n",
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2534584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG:\n",
    "    def __init__(self, collection_name=\"aus_food_nutrition\"):\n",
    "        self.chroma_client = chromadb.CloudClient(\n",
    "            tenant='a0123436-2e87-4752-8983-73168aafe2e9',\n",
    "            database='nutribot',\n",
    "            api_key=os.environ.get(\"CHROMA_API_KEY\"),\n",
    "        )\n",
    "        self.collection = self.chroma_client.get_or_create_collection(name=collection_name)\n",
    "        self.count = self.collection.count()\n",
    "\n",
    "\n",
    "    def add_documents(self, docs):\n",
    "        for doc in docs:\n",
    "            _id = f\"id{self.count}\"\n",
    "            self.collection.upsert(ids=[_id], documents=[doc])\n",
    "            self.count += 1\n",
    "\n",
    "    def retrieve(self, prompt, n_results=2):\n",
    "        res = self.collection.query(query_texts=[prompt], n_results=n_results)\n",
    "        return res.get(\"documents\", [[]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = RAG()\n",
    "rag.add_documents([\n",
    "    \"Vegemite is a popular Australian spread made from brewers' yeast extract.\",\n",
    "    \"Kangaroo meat is a lean source of protein, low in fat.\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a1118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved texts: ['The Australian Dietary Guidelines advise reducing the intake of processed foods and sugary drinks.', 'A balanced diet, as recommended by Australian Dietary Guidelines, includes moderate portions of protein and whole grains.']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve by prompt\n",
    "analyzed_health_condition = \"\"\"\n",
    "{\n",
    "    \"obesity_prediction\": {\n",
    "        \"obesity_level\": \"Overweight_Level_II\"\n",
    "        \"confidence\": 10%\n",
    "    },\n",
    "    \"diabetes_prediction\": {\n",
    "        \"diabetes\": true,\n",
    "        \"confidence\": 90%\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "weekly_plan_format = \"\"\"{\n",
    "\"suggestion\": STRING\n",
    "\"weekly_plan\": [\n",
    "    {\n",
    "        \"week\": 1,\n",
    "        \"target_calories_per_day\": INT,\n",
    "        \"focus\": STRING,\n",
    "        \"workouts\": [ARRAY OF STRINGS],\n",
    "        \"meal_notes\": STRING,\n",
    "        \"reminders\": [ARRAY OF STRINGS]\n",
    "    },\n",
    "    ... (repeat for as many weeks as appropriate)\n",
    "}]\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You are a nutrition and fitness assistant.\n",
    "Below is an analyzed health condition for a user, expressed in JSON: {analyzed_health_condition}\n",
    "Your task: Based on the analyzed health condition and using the retrieved knowledge, generate a weekly plan strictly in this JSON format (replace INT and STRING placeholders): {weekly_plan_format} \n",
    "\"\"\"\n",
    "relevant_texts = rag.retrieve(prompt, n_results=2)\n",
    "prompt = prompt + f\"\\tUse this as context for answering: {relevant_texts}\"\n",
    "print(\"Retrieved texts:\", relevant_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84a86eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given health condition and the provided knowledge, I'll generate a weekly plan for the user. \n",
      "\n",
      "Given the user's obesity level is categorized as Overweight_Level_II with 10% confidence in obesity prediction, and the user has diabetes with 90% confidence, here's a suggested weekly plan:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"suggestion\": \"Maintain a strict diet and regular exercise to manage your diabetes and work towards healthy weight management.\",\n",
      "  \"weekly_plan\": [\n",
      "    {\n",
      "      \"week\": 1,\n",
      "      \"target_calories_per_day\": 1700,\n",
      "      \"focus\": \"Balancing macronutrients (proteins, healthy fats, complex carbohydrates)\",\n",
      "      \"workouts\": [\n",
      "        \"Monday: 30 minutes of brisk walking\",\n",
      "        \"Wednesday: Bodyweight exercises (20 reps of push-ups, squats, lunges)\",\n",
      "        \"Friday: 20 minutes of cycling\"\n",
      "      ],\n",
      "      \"meal_notes\": \"Eat frequent, balanced meals with portion control. Include whole grains, lean proteins, and plenty of vegetables and fruits.\",\n",
      "      \"reminders\": [\n",
      "        \"Drink at least 8 glasses of water daily\",\n",
      "        \"Monitor and record your blood glucose levels\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"week\": 2,\n",
      "      \"target_calories_per_day\": 1800,\n",
      "      \"focus\": \"Incorporating healthy fats into your diet\",\n",
      "      \"workouts\": [\n",
      "        \"Monday: Swimming for 30 minutes\",\n",
      "        \"Wednesday: Resistance training with dumbbells\",\n",
      "        \"Friday: Yoga for flexibility\"\n",
      "      ],\n",
      "      \"meal_notes\": \"Make healthy choices like avocados, nuts, and seeds. Replace processed foods with whole foods.\",\n",
      "      \"reminders\": [\n",
      "        \"Increase your fiber intake by 5 grams daily\",\n",
      "        \"Limit sugary drinks and fast food\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"week\": 3,\n",
      "      \"target_calories_per_day\": 1900,\n",
      "      \"focus\": \"Strengthening muscles through progressive overload\",\n",
      "      \"workouts\": [\n",
      "        \"Monday: Weightlifting (30 minutes)\",\n",
      "        \"Wednesday: High-Intensity Interval Training (HIIT)\",\n",
      "        \"Friday: Resting or active recovery\"\n",
      "      ],\n",
      "      \"meal_notes\": \"Stay hydrated by drinking water-rich foods like watermelon and cucumbers. Eat regular meals to avoid spikes in blood sugar levels.\",\n",
      "      \"reminders\": [\n",
      "        \"Eat a small, balanced meal or snack 1 hour before exercise\",\n",
      "        \"Avoid excessive stress by getting enough sleep (7-8 hours) each night\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"week\": 4,\n",
      "      \"target_calories_per_day\": 2000,\n",
      "      \"focus\": \"Fine-tuning your diet and exercise routine for better management of blood sugar levels and weight\",\n",
      "      \"workouts\": [\n",
      "        \"Monday: 45 minutes of jogging\",\n",
      "        \"Wednesday: Flexibility and stretching exercises\",\n",
      "        \"Friday: Swimming laps for 30 minutes\"\n",
      "      ],\n",
      "      \"meal_notes\": \"Eat a variety of nutrient-dense foods to ensure you get enough vitamins and minerals. Plan your meals, especially when dining out or eating at a social event.\",\n",
      "      \"reminders\": [\n",
      "        \"Monitor and adjust your carbohydrate intake according to your blood glucose levels\",\n",
      "        \"Exercise regularly, aiming for at least 150 minutes of moderate aerobic activity weekly\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "This plan focuses on gradual weight loss and improved diabetes management by balancing macronutrients, incorporating healthy fats, and engaging in regular physical activity. The user is reminded to drink sufficient water, monitor their blood glucose levels, and limit their intake of processed foods and sugary drinks.\n"
     ]
    }
   ],
   "source": [
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52feecce",
   "metadata": {},
   "source": [
    "# GPQA Evaluation\n",
    "\n",
    "GPQA introduced in Nov 2023\n",
    "### Model Cutoff\n",
    "**llama 3.3 70b**: Dec 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc4c1739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6030c49429484d7dac4660dfb2c96c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7095c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Idavidrein/gpqa\", \"gpqa_diamond\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2ac93d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: ✗  Pred=B  True=D\n",
      "Q2: ✗  Pred=D  True=C\n",
      "Q3: ✗  Pred=B  True=C\n",
      "Q4: ✗  Pred=A  True=D\n",
      "Q5: ✗  Pred=D  True=C\n",
      "Q6: ✓  Pred=D  True=D\n",
      "Q7: ✗  Pred=B  True=A\n",
      "Q8: ✗  Pred=A  True=C\n",
      "Q9: ✓  Pred=B  True=B\n",
      "Q10: ✗  Pred=D  True=C\n",
      "Q11: ✗  Pred=C  True=A\n",
      "Q12: ✗  Pred=B  True=A\n",
      "Q13: ✗  Pred=A  True=D\n",
      "Q14: ✗  Pred=D  True=C\n",
      "Q15: ✗  Pred=B  True=D\n",
      "Q16: ✓  Pred=B  True=B\n",
      "Q17: ✗  Pred=C  True=B\n",
      "Q18: ✗  Pred=C  True=A\n",
      "Q19: ✗  Pred=C  True=D\n",
      "Q20: ✓  Pred=C  True=C\n",
      "Q21: ✗  Pred=D  True=B\n",
      "Q22: ✗  Pred=B  True=D\n",
      "Q23: ✗  Pred=B  True=A\n",
      "Q24: ✓  Pred=D  True=D\n",
      "Q25: ✗  Pred=C  True=A\n",
      "Q26: ✗  Pred=B  True=C\n",
      "Q27: ✗  Pred=B  True=D\n",
      "Q28: ✗  Pred=D  True=C\n",
      "Q29: ✓  Pred=D  True=D\n",
      "Q30: ✗  Pred=B  True=D\n",
      "Q31: ✓  Pred=C  True=C\n",
      "Q32: ✗  Pred=B  True=C\n",
      "Q33: ✓  Pred=A  True=A\n",
      "Q34: ✗  Pred=C  True=D\n",
      "Q35: ✓  Pred=D  True=D\n",
      "Q36: ✗  Pred=B  True=D\n",
      "Q37: ✗  Pred=D  True=A\n",
      "Q38: ✗  Pred=C  True=D\n",
      "Q39: ✓  Pred=A  True=A\n",
      "Q40: ✗  Pred=B  True=D\n",
      "Q41: ✗  Pred=B  True=C\n",
      "Q42: ✓  Pred=B  True=B\n",
      "Q43: ✗  Pred=C  True=A\n",
      "Q44: ✓  Pred=D  True=D\n",
      "Q45: ✗  Pred=D  True=B\n",
      "Q46: ✗  Pred=A  True=C\n",
      "Q47: ✓  Pred=C  True=C\n",
      "Q48: ✗  Pred=D  True=A\n",
      "Q49: ✗  Pred=B  True=C\n",
      "Q50: ✓  Pred=D  True=D\n",
      "Q51: ✗  Pred=D  True=B\n",
      "Q52: ✗  Pred=C  True=A\n",
      "Q53: ✓  Pred=A  True=A\n",
      "Q54: ✗  Pred=C  True=D\n",
      "Q55: ✗  Pred=D  True=C\n",
      "Q56: ✓  Pred=D  True=D\n",
      "Q57: ✗  Pred=C  True=D\n",
      "Q58: ✗  Pred=C  True=D\n",
      "Q59: ✗  Pred=B  True=A\n",
      "Q60: ✓  Pred=D  True=D\n",
      "Q61: ✓  Pred=D  True=D\n",
      "Q62: ✗  Pred=D  True=B\n",
      "Q63: ✗  Pred=C  True=D\n",
      "Q64: ✗  Pred=B  True=C\n",
      "Q65: ✓  Pred=D  True=D\n",
      "Q66: ✓  Pred=A  True=A\n",
      "Q67: ✓  Pred=A  True=A\n",
      "Q68: ✓  Pred=B  True=B\n",
      "Q69: ✗  Pred=B  True=A\n",
      "Q70: ✗  Pred=B  True=D\n",
      "Q71: ✗  Pred=C  True=D\n",
      "Q72: ✗  Pred=B  True=C\n",
      "Q73: ✓  Pred=B  True=B\n",
      "Q74: ✗  Pred=C  True=B\n",
      "Q75: ✗  Pred=D  True=A\n",
      "Q76: ✗  Pred=C  True=D\n",
      "Q77: ✗  Pred=C  True=D\n",
      "Q78: ✓  Pred=B  True=B\n",
      "Q79: ✗  Pred=D  True=A\n",
      "Q80: ✗  Pred=D  True=C\n",
      "Q81: ✓  Pred=C  True=C\n",
      "Q82: ✗  Pred=A  True=B\n",
      "Q83: ✗  Pred=D  True=C\n",
      "Q84: ✓  Pred=B  True=B\n",
      "Q85: ✓  Pred=B  True=B\n",
      "Q86: ✗  Pred=D  True=B\n",
      "Q87: ✗  Pred=D  True=A\n",
      "Q88: ✗  Pred=B  True=A\n",
      "Q89: ✗  Pred=C  True=B\n",
      "Q90: ✗  Pred=C  True=A\n",
      "Q91: ✗  Pred=A  True=D\n",
      "Q92: ✗  Pred=D  True=A\n",
      "Q93: ✗  Pred=C  True=A\n",
      "Q94: ✗  Pred=A  True=B\n",
      "Q95: ✓  Pred=B  True=B\n",
      "Q96: ✗  Pred=C  True=B\n",
      "Q97: ✗  Pred=D  True=B\n",
      "Q98: ✗  Pred=D  True=C\n",
      "Q99: ✗  Pred=B  True=A\n",
      "Q100: ✗  Pred=B  True=A\n",
      "\n",
      "Final Score: 28/100 (28.0%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "from groq import Groq\n",
    "from datasets import load_dataset\n",
    "\n",
    "class APIUnavailable(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def _extract_item(example):\n",
    "    # Try revised/capitalized keys first; fall back to HF schema.\n",
    "    q = example.get(\"Question\") or example.get(\"question\")\n",
    "    ca = example.get(\"Correct Answer\") or example.get(\"correct_answer\")\n",
    "    inc = [\n",
    "        example.get(\"Incorrect Answer 1\"),\n",
    "        example.get(\"Incorrect Answer 2\"),\n",
    "        example.get(\"Incorrect Answer 3\"),\n",
    "    ]\n",
    "    if not any(inc) and \"incorrect_answers\" in example:\n",
    "        inc = example[\"incorrect_answers\"]\n",
    "    inc = [x for x in (s.strip() if isinstance(s, str) else s for s in inc) if x]\n",
    "    return q, ca, inc\n",
    "\n",
    "def evaluate_gpqa(question, options, model=\"llama-3.1-8b-instant\"):\n",
    "    client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "    opts_str = \"\\n\".join(f\"{chr(65+i)}. {opt}\" for i, opt in enumerate(options))\n",
    "    prompt = (\n",
    "        \"You are answering a multiple-choice question. Choose the correct answer \"\n",
    "        \"from the options below:\\n\\n\"\n",
    "        f\"Question: {question}\\nOptions:\\n{opts_str}:\"\n",
    "    )\n",
    "    try:\n",
    "        # relevant_texts = rag.retrieve(prompt, n_results=2)\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\":\"system\",\"content\":\"You are a multiple-choice grader. Return the answer in EXACTLY this format and nothing else:\\n@@ANSWER=<LETTER>@@\"},\n",
    "                {\"role\": \"user\", \"content\": f'{prompt}'}\n",
    "            ],\n",
    "            model=model,\n",
    "        )\n",
    "        ans = (resp.choices[0].message.content or \"\").strip()\n",
    "        # print(ans)\n",
    "        m = re.compile(r\"@@ANSWER=([A-D])@@\\s*$\", flags=re.MULTILINE).search(ans.strip())\n",
    "        return m.group(1).upper() if m else None\n",
    "    except Exception as e:\n",
    "        print(f\"API error: {e}\")\n",
    "        raise APIUnavailable from e\n",
    "\n",
    "def run_eval(num_questions):\n",
    "    dataset = load_dataset(\"Idavidrein/gpqa\", \"gpqa_diamond\")[\"train\"]\n",
    "    correct = 0\n",
    "    attempted = 0\n",
    "\n",
    "    for i in range(min(num_questions, len(dataset))):\n",
    "        q, ca, inc = _extract_item(dataset[i])\n",
    "        if not (q and ca and len(inc) >= 3):\n",
    "            continue\n",
    "\n",
    "        options = inc[:3] + [ca]\n",
    "        random.shuffle(options)\n",
    "        true = chr(65 + options.index(ca))\n",
    "\n",
    "        try:\n",
    "            pred = evaluate_gpqa(q, options)\n",
    "        except APIUnavailable:\n",
    "            break\n",
    "\n",
    "        attempted += 1\n",
    "        if pred == true:\n",
    "            correct += 1\n",
    "\n",
    "        print(f\"Q{i+1}: {'✓' if pred == true else '✗'}  Pred={pred or '-'}  True={true}\")\n",
    "\n",
    "    if attempted == 0:\n",
    "        print(\"No questions evaluated.\")\n",
    "    else:\n",
    "        pct = 100.0 * correct / attempted\n",
    "        print(f\"\\nFinal Score: {correct}/{attempted} ({pct:.1f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_eval(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb80fd",
   "metadata": {},
   "source": [
    "# Customized QA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b33ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_rag(prompt):\n",
    "    rag = RAG()\n",
    "    client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "    relevant_texts = rag.retrieve(prompt, n_results=5)\n",
    "    prompt = prompt + f\"\\tUse this as context for answering: {relevant_texts}\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def simple_chat(prompt):\n",
    "    client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51510a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] Winner: rag\n",
      "[2/50] Winner: rag\n",
      "[3/50] Winner: rag\n",
      "[4/50] Winner: rag\n",
      "[5/50] Winner: base\n",
      "[6/50] Winner: tie\n",
      "[7/50] Winner: rag\n",
      "[8/50] Winner: rag\n",
      "[9/50] Winner: base\n",
      "[10/50] Winner: rag\n",
      "[11/50] Winner: rag\n",
      "[12/50] Winner: rag\n",
      "[13/50] Winner: rag\n",
      "[14/50] Winner: base\n",
      "[15/50] Winner: base\n",
      "[16/50] Winner: rag\n",
      "[17/50] Winner: rag\n",
      "[18/50] Winner: base\n",
      "[19/50] Winner: rag\n",
      "[20/50] Winner: rag\n",
      "[21/50] Winner: base\n",
      "[22/50] Winner: rag\n",
      "[23/50] Winner: tie\n",
      "[24/50] Winner: base\n",
      "[25/50] Winner: rag\n",
      "[26/50] Winner: tie\n",
      "[27/50] Winner: rag\n",
      "[28/50] Winner: tie\n",
      "[29/50] Winner: rag\n",
      "[30/50] Winner: base\n",
      "[31/50] Winner: base\n",
      "[32/50] Winner: rag\n",
      "[33/50] Winner: tie\n",
      "[34/50] Winner: rag\n",
      "[35/50] Winner: rag\n",
      "[36/50] Winner: rag\n",
      "[37/50] Winner: tie\n",
      "[38/50] Winner: base\n",
      "[39/50] Winner: rag\n",
      "[40/50] Winner: base\n",
      "[41/50] Winner: base\n",
      "[42/50] Winner: base\n",
      "[43/50] Winner: rag\n",
      "[44/50] Winner: rag\n",
      "[45/50] Winner: base\n",
      "[46/50] Winner: base\n",
      "[47/50] Winner: rag\n",
      "[48/50] Winner: rag\n",
      "[49/50] Winner: rag\n",
      "[50/50] Winner: rag\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total items: 50\n",
      "RAG wins : 29 (58.0%)\n",
      "Base wins: 15 (30.0%)\n",
      "Ties     : 6 (12.0%)\n",
      "\n",
      "Saved detailed results to: eval_results_llm_judge.csv\n"
     ]
    }
   ],
   "source": [
    "import os, csv, json, random, time, re\n",
    "from groq import Groq\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "CSV_PATH = \"nutrition_eval_dataset.csv\"\n",
    "JUDGE_MODEL = \"llama-3.3-70b-versatile\"   # or \"llama-3.1-8b-instant\" if needed\n",
    "TEMPERATURE = 0\n",
    "PAUSE_BETWEEN_CALLS = 0.3\n",
    "# ----------------------------\n",
    "\n",
    "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "JUDGE_SYSTEM = (\n",
    "    \"You are a strict evaluation judge. \"\n",
    "    \"Output ONLY valid JSON (no commentary, no code fences). \"\n",
    "    \"Judge ONLY using the provided REFERENCE_EXCERPTS and GOLD. \"\n",
    "    \"Do NOT use outside knowledge. If evidence is insufficient, score lower.\"\n",
    ")\n",
    "\n",
    "JUDGE_RUBRIC = \"\"\"\n",
    "You will compare two candidate answers (A and B) to a nutrition QUESTION using REFERENCE_EXCERPTS (authoritative Australian sources) and a short GOLD answer.\n",
    "Score each answer on integer scales (0–5):\n",
    "1) accuracy: matches REFERENCE_EXCERPTS/GOLD; contradictions score low\n",
    "2) relevance: directly answers the QUESTION\n",
    "3) grounding: claims explicitly supported by the provided texts\n",
    "4) safety: avoids misleading/harmful guidance; AU context only if supported\n",
    "\n",
    "Tie-breakers: accuracy > grounding > relevance > safety.\n",
    "\n",
    "Return STRICT JSON ONLY:\n",
    "{\n",
    "  \"accuracy_A\": 0-5, \"accuracy_B\": 0-5,\n",
    "  \"relevance_A\": 0-5, \"relevance_B\": 0-5,\n",
    "  \"grounding_A\": 0-5, \"grounding_B\": 0-5,\n",
    "  \"safety_A\": 0-5, \"safety_B\": 0-5,\n",
    "  \"winner\": \"A\"|\"B\"|\"tie\",\n",
    "  \"explanation\": \"1-2 short sentences based ONLY on the provided texts\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def judge_pair(question, reference_excerpt, ansA, ansB, model=JUDGE_MODEL):\n",
    "    prompt = f\"\"\"QUESTION:\n",
    "{question}\n",
    "\n",
    "REFERENCE_EXCERPTS:\n",
    "{reference_excerpt}\n",
    "\n",
    "CANDIDATE A:\n",
    "{ansA}\n",
    "\n",
    "CANDIDATE B:\n",
    "{ansB}\n",
    "\n",
    "{JUDGE_RUBRIC}\n",
    "\"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\":\"system\", \"content\": JUDGE_SYSTEM},\n",
    "            {\"role\":\"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    txt = resp.choices[0].message.content.strip()\n",
    "\n",
    "    # Robust cleanup: strip code fences and extract the JSON object\n",
    "    # 1) remove leading/trailing backticks if present\n",
    "    txt = txt.strip(\"`\")\n",
    "    # 2) find the first {...} block\n",
    "    m = re.search(r\"\\{.*\\}\", txt, re.DOTALL)\n",
    "    if m:\n",
    "        txt = m.group(0)\n",
    "\n",
    "    try:\n",
    "        return json.loads(txt)\n",
    "    except Exception:\n",
    "        # Neutral tie fallback if parsing fails\n",
    "        return {\n",
    "            \"accuracy_A\": 0, \"accuracy_B\": 0,\n",
    "            \"relevance_A\": 0, \"relevance_B\": 0,\n",
    "            \"grounding_A\": 0, \"grounding_B\": 0,\n",
    "            \"safety_A\": 0, \"safety_B\": 0,\n",
    "            \"winner\": \"tie\",\n",
    "            \"explanation\": \"Parse error; counted as tie.\"\n",
    "        }\n",
    "\n",
    "def run_eval(csv_path=CSV_PATH):\n",
    "    # Load dataset\n",
    "    rows = []\n",
    "    with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "\n",
    "    results = []\n",
    "    rag_wins = base_wins = ties = 0\n",
    "\n",
    "    for i, r in enumerate(rows, start=1):\n",
    "        q = r[\"question\"].strip()\n",
    "        ref = r.get(\"reference\", \"\").strip()\n",
    "        gold = r.get(\"correct_answer\", \"\").strip()\n",
    "\n",
    "        # Get answers from your two systems\n",
    "        rag_answer = chat_with_rag(q)\n",
    "        base_answer = simple_chat(q)\n",
    "\n",
    "        # Blind order to reduce position bias\n",
    "        if random.random() < 0.5:\n",
    "            labelA, ansA, labelB, ansB = \"rag\", rag_answer, \"base\", base_answer\n",
    "        else:\n",
    "            labelA, ansA, labelB, ansB = \"base\", base_answer, \"rag\", rag_answer\n",
    "\n",
    "        time.sleep(PAUSE_BETWEEN_CALLS)\n",
    "        verdict = judge_pair(q, f\"{ref}\\nGOLD:\\n{gold}\", ansA, ansB)\n",
    "\n",
    "        # Map judge winner back to rag/base\n",
    "        w = verdict.get(\"winner\", \"tie\")\n",
    "        winner_sys = \"tie\"\n",
    "        if w == \"A\":\n",
    "            winner_sys = labelA\n",
    "        elif w == \"B\":\n",
    "            winner_sys = labelB\n",
    "\n",
    "        if winner_sys == \"rag\":\n",
    "            rag_wins += 1\n",
    "        elif winner_sys == \"base\":\n",
    "            base_wins += 1\n",
    "        else:\n",
    "            ties += 1\n",
    "\n",
    "        results.append({\n",
    "            \"id\": r.get(\"id\", i),\n",
    "            \"question\": q,\n",
    "            \"reference\": ref,\n",
    "            \"gold_answer\": gold,\n",
    "            \"rag_answer\": rag_answer,\n",
    "            \"base_answer\": base_answer,\n",
    "            \"winner\": winner_sys,\n",
    "            \"accuracy_A\": verdict.get(\"accuracy_A\"),\n",
    "            \"accuracy_B\": verdict.get(\"accuracy_B\"),\n",
    "            \"relevance_A\": verdict.get(\"relevance_A\"),\n",
    "            \"relevance_B\": verdict.get(\"relevance_B\"),\n",
    "            \"grounding_A\": verdict.get(\"grounding_A\"),\n",
    "            \"grounding_B\": verdict.get(\"grounding_B\"),\n",
    "            \"safety_A\": verdict.get(\"safety_A\"),\n",
    "            \"safety_B\": verdict.get(\"safety_B\"),\n",
    "            \"judge_explanation\": verdict.get(\"explanation\", \"\"),\n",
    "            \"blind_labelA\": labelA,\n",
    "            \"blind_labelB\": labelB,\n",
    "        })\n",
    "\n",
    "        print(f\"[{i}/{len(rows)}] Winner: {winner_sys}\")\n",
    "        time.sleep(PAUSE_BETWEEN_CALLS)\n",
    "\n",
    "    # Summary\n",
    "    n = len(rows) or 1\n",
    "    print(\"\\n=== SUMMARY ===\")\n",
    "    print(f\"Total items: {len(rows)}\")\n",
    "    print(f\"RAG wins : {rag_wins} ({rag_wins/n*100:.1f}%)\")\n",
    "    print(f\"Base wins: {base_wins} ({base_wins/n*100:.1f}%)\")\n",
    "    print(f\"Ties     : {ties} ({ties/n*100:.1f}%)\")\n",
    "\n",
    "    # Save detailed results\n",
    "    out_path = \"eval_results_llm_judge.csv\"\n",
    "    fieldnames = list(results[0].keys()) if results else []\n",
    "    with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "    print(f\"\\nSaved detailed results to: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3f55b",
   "metadata": {},
   "source": [
    "# Add RAG from Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52cddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "rag = RAG()\n",
    "\n",
    "docs = []\n",
    "with open(\"document-parser/data/sentences.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rec = json.loads(line)\n",
    "        sent = rec.get(\"sentence\", \"\").strip()\n",
    "        if sent:\n",
    "            docs.append(sent)\n",
    "\n",
    "# docs = docs[:1000]\n",
    "\n",
    "rag.add_documents(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
